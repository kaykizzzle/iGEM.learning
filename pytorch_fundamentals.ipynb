{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPl2e8lLSITNYxpCmMCVsI2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaykizzzle/iGEM.learning/blob/main/pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLD20TwtkFyq",
        "outputId": "1ed89c79-6422-495d-fdf8-496505cd7085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun 27 17:38:51 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#resource notebook: https://www.learnpytorch.io/00_pytorch_fundamentals/\n"
      ],
      "metadata": {
        "id": "-uvHRkBlzCPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM4njkOZz8cM",
        "outputId": "71f3a687-31d6-4abc-a538-190f957eb044"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensors are a way to represent multidimensional data (scalar, vector, matrix, etc.)\n"
      ],
      "metadata": {
        "id": "VSX-sYeQ0roX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = torch.tensor(7)\n",
        "scalar.ndim\n",
        "scalar.item()\n",
        "\n",
        "vector = torch.tensor([7,7])\n",
        "vector.ndim  #number of dimensions is number of square brackets\n",
        "vector.shape #number of elements\n",
        "\n",
        "MATRIX = torch.tensor([[7,8],\n",
        "                       [9,10]])\n",
        "MATRIX.ndim\n",
        "MATRIX.shape\n",
        "print(MATRIX[0])\n",
        "print(MATRIX[1])\n",
        "print(MATRIX[:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuNojktn0zYB",
        "outputId": "6c782c37-f8b9-4fdb-ab21-b51270890451"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7, 8])\n",
            "tensor([ 9, 10])\n",
            "tensor([7, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR = torch.tensor([[[1,2,3],\n",
        "                    [3,6,9],\n",
        "                    [2,4,5]]])\n",
        "print(TENSOR.ndim)\n",
        "print(TENSOR.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6opndnCkNEB",
        "outputId": "7fb6554a-00ed-457f-ecba-3e232e3719d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "torch.Size([1, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###random tensors\n",
        "\n",
        "random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data."
      ],
      "metadata": {
        "id": "sL_20fjilQCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand(3,4)\n",
        "random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjr6MXnEllD1",
        "outputId": "52a9fc7b-fda5-4822-a1e8-80499c7d1ed4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4085, 0.2307, 0.1021, 0.4075],\n",
              "        [0.8055, 0.7363, 0.0658, 0.7924],\n",
              "        [0.2974, 0.8021, 0.2793, 0.7887]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a random tensor with similar shape to an image tensor\n",
        "random_image_size_tensor = torch.rand(size=(224,224,3)) #height, width, colour channels (R,G,B)\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim\n",
        "#sometimes color channels can go first, sometimes last!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYmfme1gmE5-",
        "outputId": "8862d890-0509-4cbc-bf26-9bf336efbba3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zeros and ones\n"
      ],
      "metadata": {
        "id": "17V_qT4Emo3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3,4))\n",
        "print(zeros, zeros.dtype)\n",
        "print(zeros*random_tensor)\n",
        "\n",
        "#create a tensor of all ones\n",
        "ones = torch.ones(size=(3,4))\n",
        "print(ones, ones.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgnpnsGAmr-9",
        "outputId": "e3f6ecd7-8a40-4d5a-9134-0f8fa40904be"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]]) torch.float32\n",
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating a range of tensors and tensors-like"
      ],
      "metadata": {
        "id": "OWCrntfanNrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_to_ten = torch.arange(start=0,end=1000, step=77)\n",
        "one_to_ten\n",
        "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
        "print(ten_zeros)\n",
        "# zeros in the same shape as one_to_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BRCA2acnSPu",
        "outputId": "6ec0ca06-dc0c-4da1-fdd5-1b5982ce53c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float32_tensor = torch.tensor([3.0,6.0,9.0], dtype=None, device=None, requires_grad=False)\n",
        "print(float32_tensor)\n",
        "#dtype is what datatype the tensor is (most common is 16b and 32b), deal with precision and computing\n",
        "#device can be cuda or cpu (need to be the same for all compatible tensors)\n",
        "#requires_grad true or false, do we want pytorch to track the gradients as the tensor undergoes calculations?\n",
        "float_16_tensor = float32_tensor.type(torch.float16)\n",
        "print(float_16_tensor) #switch from 32b data type to 16b data type\n",
        "\n",
        "#you can perform some operations where the data types are different but some\n",
        "# data types aren't compatible for certain operations!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3eCsVjGn0r-",
        "outputId": "8442f7f1-737f-4445-99af-0527fc9fc884"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 6., 9.])\n",
            "tensor([3., 6., 9.], dtype=torch.float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Manipulating tensors\n",
        "\n",
        "Include...\n",
        "\n",
        "\n",
        "*   addition\n",
        "*   subtraction\n",
        "\n",
        "\n",
        "*   multiplication/division\n",
        "*   matrix multiplication (dot product)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HHalykI4u4bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1,2,3])\n",
        "print(tensor + 10,\n",
        "tensor - 10,\n",
        "tensor * 10,\n",
        "tensor / 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jSnyAsLu51X",
        "outputId": "24742bfc-6149-4db5-897c-67a61280eb0e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([11, 12, 13]) tensor([-9, -8, -7]) tensor([10, 20, 30]) tensor([0.1000, 0.2000, 0.3000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor)\n",
        "#element wise multiplication\n",
        "print(tensor * tensor)\n",
        "#matrix multiplication\n",
        "print(torch.matmul(tensor,tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWvvQYpnvWIB",
        "outputId": "f91dc1d9-67cf-40b0-eb54-5c0a7d21b34d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "tensor([1, 4, 9])\n",
            "tensor(14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###shape errors...\n",
        "one of the most common errors in matrix multiplications\n",
        "1. the inner dimensions must match (3,2) @ (2,3) will work but (3,2) @ (3,2) WONT work\n",
        "2. resulting matrix has the shape of the outer dimensions"
      ],
      "metadata": {
        "id": "woGZQQOLwyqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transposing the matrix fixes shape issues"
      ],
      "metadata": {
        "id": "XyelF8P7yLPN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.rand(3,2)\n",
        "tensor2 = torch.rand(3,2)\n",
        "tensor3 = tensor2.T #flips dimensions\n",
        "print(torch.mm(tensor1, tensor3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAB24s15yNhf",
        "outputId": "6d8cc5a9-787c-4a81-e0d1-6413e6a3e521"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4003, 0.3175, 0.4612],\n",
            "        [0.1168, 0.1639, 0.1925],\n",
            "        [0.5146, 0.4981, 0.6661]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tensor Aggregation"
      ],
      "metadata": {
        "id": "KGxzbLn6zWMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(0,100,10)\n",
        "print(x,\n",
        "x.min(),\n",
        "x.max(),\n",
        "torch.mean(x.type(torch.float32)),\n",
        "x.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-0EAOWHzX3P",
        "outputId": "8d80f8a9-ba11-4abf-f9c9-0cf4db4a40e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]) tensor(0) tensor(90) tensor(45.) tensor(450)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Find positional min and max"
      ],
      "metadata": {
        "id": "p1vY5HlD0OXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n",
        "print(x.argmin())\n",
        "#returns index position of target tensor where minimum value occurs, argmax does the same with the max value\n",
        "print(x.argmax())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfShvLYY0Qfl",
        "outputId": "8e33d9f3-f707-4aaa-c069-3cae1eb38e12"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "tensor(0)\n",
            "tensor(9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Reshaping, stacking, squeezing, and unsqueezing\n",
        "\n",
        "- reshaping = reshapes an input tesnor to a defined shape\n",
        "- view = return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
        "- stacking = combine multiple tesnors ontop or side by side (vstack or hstack)\n",
        "- squeeze = remove all '1' dimensions from a tensor\n",
        "- unsqueeze = add a '1' dimension to a target tensor\n",
        "- permute = return a view of the input with dimensions permuted (swapped) in a certain way"
      ],
      "metadata": {
        "id": "z8GyDd7B1opt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape\n",
        "y = torch.arange(1,11) #only from 1 to 10\n",
        "print(y)\n",
        "print(y.shape)\n",
        "print(y.reshape(5,2), y.reshape(2,5), y.reshape(1,10))\n",
        "#want the reshape to multiply to equal the shape\n",
        "\n",
        "#change the view\n",
        "z = y.view(1,10)\n",
        "print(z) #changing z changes y because a view of tensor shares the same memory as the original\n",
        "\n",
        "#stack tensors on top of each other\n",
        "y_stacked = torch.stack([y,y,y,y], dim=0)\n",
        "print(y_stacked)\n",
        "\n",
        "#squeeze tensors, fix dimension mismatch!\n",
        "y_reshaped = y.reshape(1,10)\n",
        "y_squeezed = y_reshaped.squeeze()\n",
        "print(y_reshaped.shape, y_squeezed.shape)\n",
        "\n",
        "#unsqueeze tensors, fix dimension mismatch!\n",
        "# adds a single dimension to a target tensor at a specific dimension\n",
        "y_unsqueezed = y_squeezed.unsqueeze(dim=1)\n",
        "print(y_unsqueezed.shape)\n",
        "\n",
        "#permute rearranges the dimensions in a certain order\n",
        "x_original = torch.rand(size=(224,224,3)) #height, width, color channels\n",
        "print(x_original.size())\n",
        "x_permuted = x_original.permute(2,0,1) #second dimension is first, 0th dimension is second, first dimension is third\n",
        "print(x_permuted.size()) #color channels, height, width"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUDvvanC1rsW",
        "outputId": "fa8fe5e8-7dbf-4039-83e3-44a44e650998"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
            "torch.Size([10])\n",
            "tensor([[ 1,  2],\n",
            "        [ 3,  4],\n",
            "        [ 5,  6],\n",
            "        [ 7,  8],\n",
            "        [ 9, 10]]) tensor([[ 1,  2,  3,  4,  5],\n",
            "        [ 6,  7,  8,  9, 10]]) tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
            "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
            "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n",
            "torch.Size([1, 10]) torch.Size([10])\n",
            "torch.Size([10, 1])\n",
            "torch.Size([224, 224, 3])\n",
            "torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Indexing (selecting data from tensors)"
      ],
      "metadata": {
        "id": "3Ftyjgem7i0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(1,10).reshape(1,3,3)\n",
        "print(x, x.shape)\n",
        "print(x[0])\n",
        "print(x[0][0])\n",
        "print(x[0][0][0])\n",
        "print(x[0][2][2])\n",
        "\n",
        "#get all in the 0th dimension and only index 0 of the first dimenstion\n",
        "print(x[:,0])\n",
        "#get all in the 0th and 1st dimensions and only index 1 of the 2nd dimension\n",
        "print(x[:,:,1])\n",
        "#get only 9\n",
        "print(x[:,2,2])\n",
        "#get 3,6,9\n",
        "print(x[:,:,2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGZvcQr-7w0I",
        "outputId": "660e48e0-4e35-4adf-e5a5-1b1b1cfdd3b1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]]) torch.Size([1, 3, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "tensor([1, 2, 3])\n",
            "tensor(1)\n",
            "tensor(9)\n",
            "tensor([[1, 2, 3]])\n",
            "tensor([[2, 5, 8]])\n",
            "tensor([9])\n",
            "tensor([[3, 6, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pytorch tensors and numpy\n",
        "numpy is a popular scientific python numerical computing library\n",
        "because of this, pytorch has functionality to interact with it\n",
        "- data in numpy, want in pytorch tensor -> torch.from_numpy(ndarray)\n",
        "-pytorch tensor -> numpy -> torch.Tensor.numpy()"
      ],
      "metadata": {
        "id": "bvFf_XhA9zzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#numpy array to tensor\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "array = np.arange(1.0,8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "print(array, tensor)\n",
        "#numpys default datatype is float64\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4HaxfwT-ak2",
        "outputId": "9fa875db-b063-462b-c0de-18ef194118f1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 2. 3. 4. 5. 6. 7.] tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Putting tensors and models on the GPU\n",
        "\n",
        "Using a GPU results in faster calculations"
      ],
      "metadata": {
        "id": "zgp6IcSHwsY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1,2,3])\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "#create \"device\" parameter (moves to GPU if possible, keeps on CPU if necessary)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#move to the GPU/target device\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "print(tensor_on_gpu, tensor_on_gpu.device)\n",
        "\n",
        "#move tensor back to CPU (can't transform tensor to numpy when on GPU)\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "print(tensor_back_on_cpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dteHR_kww6oV",
        "outputId": "ee3e0d66-abeb-4711-b32f-31c0d03c3152"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n",
            "tensor([1, 2, 3], device='cuda:0') cuda:0\n",
            "[1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PyTorch workflow\n",
        "\n",
        "1. get data ready (turn into tensors)\n",
        "2. build or pick a pretrained model (to suit your problem), pick a loss function and optimizer, build a training loop\n",
        "3. fit the model to the data and make a prediction\n",
        "4. evaluate the model\n",
        "5. improve through experimentation\n",
        "6. save and reload your trained model\n",
        "\n"
      ],
      "metadata": {
        "id": "-6CSE5mEyiUW"
      }
    }
  ]
}